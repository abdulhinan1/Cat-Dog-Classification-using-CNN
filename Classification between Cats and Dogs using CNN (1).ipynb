{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bb0725",
   "metadata": {},
   "source": [
    "### Load the requird Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c12f256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce6b241",
   "metadata": {},
   "source": [
    "\n",
    "## Set the path where our Train,Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e4a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desktop path\n",
    "desktop_path = os.path.expanduser('~/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a23606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the zip file names\n",
    "train_zip = os.path.join(desktop_path, 'train.zip')\n",
    "test_zip = os.path.join(desktop_path, 'test.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855a6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the extraction directories\n",
    "train_dir = os.path.join(desktop_path, 'train1')\n",
    "test_dir = os.path.join(desktop_path, 'test1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a717c0",
   "metadata": {},
   "source": [
    "## Extract the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f201ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the train and test data from the zip files\n",
    "with zipfile.ZipFile(train_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475a1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(test_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ace668",
   "metadata": {},
   "source": [
    "## Set the Image Size,Batch_size,Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81272901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Set the batch size and number of epochs\n",
    "batch_size = 32\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa55404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d3f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb8f62f2",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedefbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an ImageDataGenerator for data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,     # Normalize pixel values to [0, 1]\n",
    "    shear_range=0.2,       # Apply shear transformation\n",
    "    zoom_range=0.2,        # Apply zoom transformation\n",
    "    horizontal_flip=True   # Flip images horizontally\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Load and augment the training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'   # Set the class mode to 'binary' for binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2d93ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the test data without augmentation\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e3ab6",
   "metadata": {},
   "source": [
    "## Define CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6fa0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0820f8",
   "metadata": {},
   "source": [
    "## Model Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4daa80f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 5538s 7s/step - loss: 8.9664e-04 - accuracy: 0.9991 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 2536s 3s/step - loss: 1.9214e-29 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 3698s 5s/step - loss: 5.1595e-31 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 2477s 3s/step - loss: 1.0073e-30 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 2127s 3s/step - loss: 7.7774e-30 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 1916s 2s/step - loss: 1.9173e-31 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 36696s 47s/step - loss: 5.3603e-31 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 1764s 2s/step - loss: 1.1087e-29 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 1953s 2s/step - loss: 7.9877e-28 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 1642s 2s/step - loss: 5.2900e-31 - accuracy: 1.0000 - val_loss: 2.0052e-29 - val_accuracy: 1.0000\n",
      "391/391 [==============================] - 192s 490ms/step - loss: 2.0052e-29 - accuracy: 1.0000\n",
      "Test Loss: 2.0052006190451069e-29\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=epochs, validation_data=test_generator)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e6d01",
   "metadata": {},
   "source": [
    "## Predicted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_image_paths = ['C:\\\\Users\\\\ahina\\\\Desktop\\\\cat.0.jpg', 'C:\\\\Users\\\\ahina\\\\Desktop\\\\dog.2500.jpg','C:\\\\Users\\\\ahina\\\\Desktop\\\\cat.53.jpg',\n",
    "                   'C:\\\\Users\\\\ahina\\\\Desktop\\\\dog.2496.jpg']\n",
    "new_images = []\n",
    "\n",
    "for image_path in new_image_paths:\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    img = cv2.resize(img, (img_width, img_height))\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Failed to resize image: {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    img = img.astype('float32') / 255.0\n",
    "    new_images.append(img)\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ef00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08185a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
